# AI Model Configuration
# Choose your preferred AI model: 'llama' or 'gemini'
AI_MODEL_TYPE=llama

# Llama/Ollama API Configuration (Primary)
LLAMA_API_URL=http://localhost:11434
LLAMA_API_KEY=your-llama-api-key-here

# Ollama Model Configuration
# Available models: phi3:3.8b, llama3.2:3b, llama3.2:1b, etc.
OLLAMA_MODEL=phi3:3.8b

# Phi Model Specific Settings
PHI_TEMPERATURE=0.7
PHI_MAX_TOKENS=1000
PHI_TOP_P=0.9

# Google Gemini API Configuration (Fallback)
GEMINI_API_KEY=your-google-gemini-api-key-here

# Instructions:
# 1. Copy this file to .env
# 2. Set AI_MODEL_TYPE to 'llama' to use Llama 3.2 or 'gemini' to use Google Gemini
# 3. For Llama 3.2:
#    - Set LLAMA_API_URL to your Llama server endpoint (default: http://localhost:8000)
#    - Set LLAMA_API_KEY if your server requires authentication
# 4. For Gemini:
#    - Get your API key from: https://makersuite.google.com/app/apikey
#    - Replace 'your-google-gemini-api-key-here' with your actual key

# Examples:
# AI_MODEL_TYPE=llama
# LLAMA_API_URL=http://localhost:8000
# LLAMA_API_KEY=optional-if-auth-required
# GEMINI_API_KEY=AIzaSyC1234567890abcdefghijklmnopqrstuvwxyz